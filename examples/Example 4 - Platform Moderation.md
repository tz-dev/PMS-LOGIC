# Example 4 — Platform Moderation: Authority Capture via “We’re Just Being Rational”

## 1. Scene (Praxeological Setup)
- **Context:** A large online platform enforces content moderation policies using algorithmic scoring and internal guidelines.
- **Stakes:** Speech visibility, account access, reputational and economic effects at scale.
- **What is structurally at issue (not morally):** How logical procedures and metrics become authority under asymmetry, without introducing norms.

## 2. Frame Validity (□)
- **Role space:** Platform moderators, policy teams, automated systems, affected users.
- **Scope boundaries:** Terms of service, enforcement pipelines, appeal mechanisms, latency constraints.
- **What is out of frame:** Comprehensive truth adjudication, moral evaluation of speech, societal consensus.

## 3. Structural Facts (Δ, Λ, Α)
- **Key distinctions (Δ):**
  - Allowed vs. restricted content.
  - Flagged vs. unflagged behavior.
- **Expected non-events / omissions (Λ):**
  - Absence of case-specific justification for many decisions.
  - Non-delivery of individualized explanations within time windows.
- **Stabilized patterns / attractors (Α):**
  - Recurrent reliance on scores, thresholds, and precedents.
  - Habitual deferral to “policy says so.”

## 4. Asymmetry & Temporality (Ω, Θ)
- **Exposure gradients (Ω):**
  - Platform decisions disproportionately affect users with limited recourse.
- **Capacity gradients (Ω):**
  - Enforcement capacity exceeds user capacity to contest or understand outcomes.
- **Irreversibility / closing windows (Θ):**
  - Visibility loss and account actions have lasting effects; appeals are time-bound.

## 5. Where “Moral Readability” Emerges (Post-Moral Field)
- **Why consequences become attributable (without “ought”):**
  - Concentrated enforcement capacity under time renders outcomes traceable to platform trajectories.
- **How omission/non-action becomes non-neutral:**
  - Failure to review, explain, or correct decisions functions as Λ within the frame.

## 6. Logic’s Legitimate Limit (Λ as boundary)
- **What cannot be closed inside the frame:**
  - Metrics cannot exhaust meaning, context, or downstream effects.
- **Where closure-pressure appears (∇ → Σ-totalization risk):**
  - “Rational necessity” rhetoric used to seal decisions against contestation.

## 7. Boundary Management Operators (Φ, Χ, Σ, Ψ)
- **Minimal recontextualization (Φ) (if needed):**
  - From “objective enforcement” to “capacity-bounded governance.”
- **Distance enforcement (Χ):**
  - Preventing metric outputs from becoming justificatory authority.
- **Integration without totalization (Σ):**
  - Coordinating rules, signals, and uncertainty without claiming completeness.
- **Self-binding as attribution-stability (Ψ):**
  - Owning long-term effects across policy iterations and appeals.

## 8. Typical Misreads / Failure Modes
- **Dogmatism (Σ→total closure):**
  - Treating models as final arbiters.
- **Moralism (pseudo-ought injection):**
  - Converting enforcement into moral condemnation.
- **Nihilism (Λ-suppression):**
  - Denying omission effects (“the system decided”).
- **Authority capture (Ω→epistemic authority):**
  - Power laundering through “logic.”
- **Frame lock (□-overconstraint):**
  - Assuming platform frames exhaust public meaning.

## 9. PMS–LOGIC Output (Allowed Outputs Only)
- **Structural mapping:** Δ/Λ/Α under Ω and Θ; Χ/Σ constrain closure.
- **Attribution conditions (capacity-bounded):** Responsibility tracks enforcement capacity and persistence.
- **What remains open (Λ carried):** Contextual remainder and appeal gaps.
- **No prescriptions, no rankings, no sanctions:** Moral readability without “ought.”

## 10. Conclusion (PMS–LOGIC Takeaway)

This case shows with particular clarity how **logic turns into authority** when its structural limits are not carried. The platform does not appear morally charged because it enforces values or issues commands, but because it holds **concentrated, persistent capacity (Ω)** over users’ visibility and access, exercised across **irreversible time (Θ)**. Once this capacity is in place, moderation outcomes—actions *and omissions*—become structurally attributable, regardless of whether anyone intended moral judgment.

The central mechanism is **authority capture via logic**. Metrics, thresholds, and procedural rules are legitimate tools of integration (Σ): they reduce complexity and enable scalable coordination. The failure occurs when these tools are rhetorically elevated into **justificatory closure**—“the system is rational,” “the model decided,” “policy required it.” At that point, **Λ is denied**. The persistent remainder—unmodeled context, lost nuance, downstream harm—does not disappear, but becomes invisible, displaced, or externalized.

Moral readability emerges precisely here. Users experience moderation as “moralized” not because norms are stated, but because **consequences are asymmetric and durable** while explanation is withheld. The **non-event (Λ)**—missing justification, absent review, silence in appeals—functions as an active structural element. It stabilizes outcomes while blocking contestation, making responsibility legible even in the absence of explicit blame or sanction.

PMS–LOGIC clarifies why neither of the common counter-moves works. Declaring enforcement “purely technical” is a form of **Λ-suppression**: it denies that omissions and opacity matter under Ω and Θ. Conversely, condemning moderation as moral censorship injects a **pseudo-ought**, collapsing attribution into accusation. Both miss the structural point. Responsibility here tracks **effective enforcement capacity over time**, not moral intent and not algorithmic necessity.

Distance (Χ) is therefore decisive. Without Χ, integration (Σ) slides into totalization: models become final arbiters, and asymmetry (Ω) is laundered into epistemic authority. With Χ, logic remains what PMS–LOGIC allows it to be: a boundary-management instrument that coordinates action while openly carrying Λ. Recontextualization (Φ) then becomes possible—seeing moderation not as truth enforcement, but as **capacity-bounded governance under uncertainty**.

Self-binding (Ψ) stabilizes attribution across time. Even as policies change and systems evolve, responsibility does not reset with each update. The platform remains a continuous trajectory that owns the effects of its enforcement patterns and omissions. This is not moral condemnation; it is **structural non-innocence** under persistent capacity.

The moderation case thus crystallizes a core warning of PMS–LOGIC: when logic is allowed to masquerade as authority, morality reappears in distorted form—through resentment, accusation, and legitimacy crises. The alternative is not norm-setting, but discipline: **carry Λ, maintain Χ, integrate without totalization, and bind responsibility to capacity over time**. Moral readability then emerges as an unavoidable effect of structure, not as a verdict imposed from above.
